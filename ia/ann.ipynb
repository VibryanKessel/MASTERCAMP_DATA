{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/alz02/Documents/MasterCamp/MC_Prj/MASTERCAMP_DATA/ia/ann.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alz02/Documents/MasterCamp/MC_Prj/MASTERCAMP_DATA/ia/ann.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m make_blobs, make_circles\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alz02/Documents/MasterCamp/MC_Prj/MASTERCAMP_DATA/ia/ann.ipynb#ch0000000?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, log_loss\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alz02/Documents/MasterCamp/MC_Prj/MASTERCAMP_DATA/ia/ann.ipynb#ch0000000?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alz02/Documents/MasterCamp/MC_Prj/MASTERCAMP_DATA/ia/ann.ipynb#ch0000000?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation(dimensions):\n",
    "    \n",
    "    parametres = {}\n",
    "    C = len(dimensions)\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    for c in range(1, C):\n",
    "        parametres['W' + str(c)] = np.random.randn(dimensions[c], dimensions[c - 1])\n",
    "        parametres['b' + str(c)] = np.random.randn(dimensions[c], 1)\n",
    "\n",
    "\n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parametres):\n",
    "  \n",
    "  activations = {'A0': X}\n",
    "  \n",
    "  C = len(parametres) // 2\n",
    "  \n",
    "  for c in range(1, C + 1):\n",
    "\n",
    "    Z = parametres['W' + str(c)]*activations['A' + str(c - 1)] + parametres['b' + str(c)]\n",
    "    activations['A' + str(c)] = 1 / (1 + np.exp(-Z))\n",
    "\n",
    "  return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(y, parametres, activations):\n",
    "\n",
    "  m = y.shape[1]\n",
    "  C = len(parametres) // 2\n",
    "\n",
    "  dZ = activations['A' + str(C)] - y\n",
    "  gradients = {}\n",
    "\n",
    "  for c in reversed(range(1, C + 1)):\n",
    "    gradients['dW' + str(c)] = 1/m * np.dot(dZ, activations['A' + str(c - 1)].T)\n",
    "    gradients['db' + str(c)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    if c > 1:\n",
    "      dZ = np.dot(parametres['W' + str(c)].T, dZ) * activations['A' + str(c - 1)] * (1 - activations['A' + str(c - 1)])\n",
    "\n",
    "  return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(gradients, parametres, learning_rate):\n",
    "\n",
    "    C = len(parametres) // 2\n",
    "\n",
    "    for c in range(1, C + 1):\n",
    "        parametres['W' + str(c)] = parametres['W' + str(c)] - learning_rate * gradients['dW' + str(c)]\n",
    "        parametres['b' + str(c)] = parametres['b' + str(c)] - learning_rate * gradients['db' + str(c)]\n",
    "\n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parametres):\n",
    "  activations = forward_propagation(X, parametres)\n",
    "  C = len(parametres) // 2\n",
    "  Af = activations['A' + str(C)]\n",
    "  return Af >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_network(X, y, hidden_layers = (16, 16, 16), learning_rate = 0.001, n_iter = 3000):\n",
    "\n",
    "    print(X[0][0])\n",
    "    # initialisation parametres\n",
    "    dimensions = list(hidden_layers)\n",
    "    dimensions.insert(0, X.shape[0])\n",
    "    dimensions.append(y.shape[0])\n",
    "    np.random.seed(1)\n",
    "    parametres = initialisation(dimensions)\n",
    "\n",
    "    # tableau numpy contenant les futures accuracy et log_loss\n",
    "    training_history = np.zeros((int(n_iter), 2))\n",
    "\n",
    "    C = len(parametres) // 2\n",
    "\n",
    "    # gradient descent\n",
    "    for i in tqdm(range(n_iter)):\n",
    "\n",
    "        activations = forward_propagation(X, parametres)\n",
    "        gradients = back_propagation(y, parametres, activations)\n",
    "        parametres = update(gradients, parametres, learning_rate)\n",
    "        Af = activations['A' + str(C)]\n",
    "\n",
    "        # calcul du log_loss et de l'accuracy\n",
    "        training_history[i, 0] = (log_loss(y.flatten(), Af.flatten()))\n",
    "        y_pred = predict(X, parametres)\n",
    "        training_history[i, 1] = (accuracy_score(y.flatten(), y_pred.flatten()))\n",
    "\n",
    "    # Plot courbe d'apprentissage\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_history[:, 0], label='train loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_history[:, 1], label='train acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions de X: (5, 1000)\n",
      "dimensions de y: (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('./master_camp_db_femmes/nombre_de_repas/perte.csv','r') as f:\n",
    "    \n",
    "    data = list(csv.reader(f))[1:]\n",
    "    for el in data:\n",
    "        \"\"\" a = int(int(el[-2])/int(el[-1]))\n",
    "        b = int((int(el[-2])+150)/int(el[-1]))\n",
    "        c = [a,b]\n",
    "         \"\"\"\n",
    "        el = list(map(int,el))\n",
    "        \n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "t = len(data[0])-2\n",
    "\n",
    "X = data[:,:t]\n",
    "y = data[:,-1]\n",
    "\n",
    "X = X.T\n",
    "y = y.reshape((1, y.shape[0]))\n",
    "\n",
    "print('dimensions de X:', X.shape)\n",
    "print('dimensions de y:', y.shape)\n",
    "\n",
    "\n",
    "\n",
    "#plt.scatter(X[:,0],X[:,1] ,c=y, cmap='summer')\n",
    "#\n",
    "# \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('float64'), dtype('<U4')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeep_neural_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [125]\u001b[0m, in \u001b[0;36mdeep_neural_network\u001b[0;34m(X, y, hidden_layers, learning_rate, n_iter)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# gradient descent\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_iter)):\n\u001b[0;32m---> 19\u001b[0m     activations \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparametres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m back_propagation(y, parametres, activations)\n\u001b[1;32m     21\u001b[0m     parametres \u001b[38;5;241m=\u001b[39m update(gradients, parametres, learning_rate)\n",
      "Input \u001b[0;32mIn [128]\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(X, parametres)\u001b[0m\n\u001b[1;32m      5\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(parametres) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, C \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m   Z \u001b[38;5;241m=\u001b[39m \u001b[43mparametres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m parametres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(c)]\n\u001b[1;32m     10\u001b[0m   activations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(c)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mZ))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m activations\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('float64'), dtype('<U4')) -> None"
     ]
    }
   ],
   "source": [
    "deep_neural_network(X, y, hidden_layers = (2,1), learning_rate = 0.1, n_iter = 3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
